{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Manejo de Errores"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Con la clase creada en el módulo 7, tener en cuenta diferentes casos en que el código pudiera arrojar error. Por ejemplo, en la creación del objeto recibimos una lista de números enteros pero ¿qué pasa si se envía otro tipo de dato?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "\n",
    "sys.path.append(r'C:\\Users\\pablo\\Desktop\\Henry\\repos\\Original\\Python-Prep\\07 - Clases & OOP')\n",
    "import herramientas_ as h"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<module 'herramientas_' from 'C:\\\\Users\\\\pablo\\\\Desktop\\\\Henry\\\\repos\\\\Original\\\\Python-Prep\\\\07 - Clases & OOP\\\\herramientas_.py'>"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import importlib\n",
    "importlib.reload(h)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "h1 = h.Herramientas([2,4,5,5,7,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[2, 24, 120, 120, 5040, 1]"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "h1.factorial()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5, 2)"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "h1.mas_repetido()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. En la función que hace la conversión de grados, validar que los parámetros enviados sean los esperados, de no serlo, informar cuáles son los valores esperados."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2 grados celsius son 275.15 grados kelvin\n",
      "4 grados celsius son 277.15 grados kelvin\n",
      "5 grados celsius son 278.15 grados kelvin\n",
      "5 grados celsius son 278.15 grados kelvin\n",
      "7 grados celsius son 280.15 grados kelvin\n",
      "1 grados celsius son 274.15 grados kelvin\n"
     ]
    }
   ],
   "source": [
    "h1.conversion_grados('celsius', 'kelvin')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Valores invalidos : los valores validos son : ['celsius', 'farenheit', 'kelvin'] y el  \n",
      "                  valor de origen y el de destino deben ser distintos\n"
     ]
    }
   ],
   "source": [
    "h1.conversion_grados('hola', 'juan')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. Importar el modulo \"unittest\" y crear los siguientes casos de pruebas sobre la clase utilizada en el punto 2<br>\n",
    "Creacion del objeto incorrecta<br>\n",
    "Creacion correcta del objeto<br>\n",
    "Metodo valor_modal()<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "import unittest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TestHerramientas(unittest.TestCase):\n",
    "    def test_crear_objeto1(self):\n",
    "        param = 'hola'\n",
    "        self.assertRaises(ValueError, h.Herramientas, param)\n",
    "        #self.failUnlessRaises(ValueError, h.Herramientas, param)\n",
    "\n",
    "    def test_crear_objeto2(self):\n",
    "        param = [1,2,2,5]\n",
    "        h1 = h.Herramientas(param)\n",
    "        self.assertEqual(h1.lista, param)\n",
    "    \n",
    "    def test_mas_repetido(self):\n",
    "        param = [1,2,3,3,3,4,4,1]\n",
    "        h1 = h.Herramientas(param)\n",
    "        mas_rep , veces = h1.mas_repetido()\n",
    "        result_f = [mas_rep, veces]\n",
    "        result = [3, 3]\n",
    "        self.assertEqual(result_f, result)\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "test_crear_objeto1 (__main__.TestHerramientas) ... ok\n",
      "test_crear_objeto2 (__main__.TestHerramientas) ... ok\n",
      "test_mas_repetido (__main__.TestHerramientas) ... ok\n",
      "test_lista_primos (__main__.TestHerramientas2) ... ok\n",
      "\n",
      "----------------------------------------------------------------------\n",
      "Ran 4 tests in 0.057s\n",
      "\n",
      "OK\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<unittest.main.TestProgram at 0x2728a287910>"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unittest.main(argv = ' ' , verbosity=3 ,  exit = False)\n",
    "    "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4. Probar una creación incorrecta y visualizar la salida del \"raise\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Se ha creado una lista vacía. Se esperaba una lista de núemeros enteros",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[106], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m h2 \u001b[39m=\u001b[39m h\u001b[39m.\u001b[39;49mHerramientas(\u001b[39m'\u001b[39;49m\u001b[39malgo\u001b[39;49m\u001b[39m'\u001b[39;49m)\n",
      "File \u001b[1;32m~\\Desktop\\Henry\\repos\\Original\\Python-Prep\\07 - Clases & OOP\\herramientas_.py:9\u001b[0m, in \u001b[0;36mHerramientas.__init__\u001b[1;34m(self, lista_numeros)\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mtype\u001b[39m(lista_numeros) \u001b[39m!=\u001b[39m \u001b[39mlist\u001b[39m :\n\u001b[0;32m      8\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mlista \u001b[39m=\u001b[39m []\n\u001b[1;32m----> 9\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\u001b[39m'\u001b[39m\u001b[39mSe ha creado una lista vacía. Se esperaba una lista de núemeros enteros\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[0;32m     10\u001b[0m \u001b[39melse\u001b[39;00m:    \n\u001b[0;32m     11\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mlista \u001b[39m=\u001b[39m lista_numeros\n",
      "\u001b[1;31mValueError\u001b[0m: Se ha creado una lista vacía. Se esperaba una lista de núemeros enteros"
     ]
    }
   ],
   "source": [
    "h2 = h.Herramientas('algo')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "6. Agregar casos de pruebas para el método verifica_primos() realizando el cambio en la clase, para que devuelva una lista de True o False en función de que el elemento en la posisicón sea o no primo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TestHerramientas2(unittest.TestCase):\n",
    "    def test_lista_primos(self) :\n",
    "        param = [1,2,3,4,5,5,8,8,7,2,1]\n",
    "        h1 = h.Herramientas(param)\n",
    "        mi_result = h1.lista_primos()\n",
    "        result= [2,3,5,5,7,2]\n",
    "        self.assertEqual(mi_result, result)\n",
    "        \n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "test_crear_objeto1 (__main__.TestHerramientas) ... ok\n",
      "test_crear_objeto2 (__main__.TestHerramientas) ... ok\n",
      "test_mas_repetido (__main__.TestHerramientas) ... ok\n",
      "test_lista_primos (__main__.TestHerramientas2) ... ok\n",
      "\n",
      "----------------------------------------------------------------------\n",
      "Ran 4 tests in 0.018s\n",
      "\n",
      "OK\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<unittest.main.TestProgram at 0x2728a2875b0>"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unittest.main(argv = ' ' , verbosity=3 ,  exit = False) # Es muy util acomodé varios errores"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "8. Agregar casos de prueba para el metodo factorial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<module 'herramientas_' from 'C:\\\\Users\\\\pablo\\\\Desktop\\\\Henry\\\\repos\\\\Original\\\\Python-Prep\\\\07 - Clases & OOP\\\\herramientas_.py'>"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "importlib.reload(h)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TestHerramientas2(unittest.TestCase):  # Volví a acomodar errores \n",
    "    def test_lista_factorial(self) :\n",
    "        param = [1,2,3,4,5,6,7,6, 4, 2, 3, 1, 0]\n",
    "        h1 = h.Herramientas(param)\n",
    "        mi_result = h1.factorial()\n",
    "        result= [1, 2, 6, 24, 120, 720, 5040, 720, 24, 2, 6, 1, 1]\n",
    "        self.assertEqual(mi_result, result)\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "test_crear_objeto1 (__main__.TestHerramientas) ... ok\n",
      "test_crear_objeto2 (__main__.TestHerramientas) ... ok\n",
      "test_mas_repetido (__main__.TestHerramientas) ... ok\n",
      "test_lista_factorial (__main__.TestHerramientas2) ... ok\n",
      "\n",
      "----------------------------------------------------------------------\n",
      "Ran 4 tests in 0.771s\n",
      "\n",
      "OK\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<unittest.main.TestProgram at 0x2728a350be0>"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unittest.main(argv = ' ' , verbosity=3 ,  exit = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "b2e652f635080af47a587503e30de6976439f49ada01b3349f0f0746ac93a74c"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
